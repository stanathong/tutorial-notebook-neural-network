{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What CNN See\n",
    "\n",
    "This notebook is based solely from the content presented in https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html by _Francois Chollet_ and https://github.com/keras-team/keras/blob/master/examples/conv_filter_visualization.py.\n",
    "\n",
    "Some extra content have been added from the original content to aid my understanding of using __Keras__.  \n",
    "\n",
    "This notebook visualises what deep convolutional neural networks see from the images we feed them.  \n",
    "\n",
    "We will start by defining the VGG16 model in Keras by  \n",
    "\n",
    "(1) Import Keras applications using the command<br>\n",
    "`from keras import applications`<br>\n",
    "Keras Applications are deep learning models that are made available alongside pre-trained weights.\n",
    "\n",
    "(2) Instantiate a VGG16 model (performing this, weights are downloaded automatically to ~/.keras/models/.<br>\n",
    "```\n",
    "keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "```\n",
    "* include_top: whether to include the 3 fully-connected layers at the top (end) of the network. _In this code, we set `include_top = False`. This is because adding the FC layers requires us to use a fixed input size for the model (i.e. 224x244, the original ImageNet format).  \n",
    "* weights: it can be `None` for random initilisation or `imagenet` for pre-trained weights on ImageNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supannee/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "\n",
    "# Build the VGG16 network\n",
    "model = applications.VGG16(include_top = False,\n",
    "                          weights = 'imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary for (layer.name, layer) using layer.name as key because each layer has a unique name. We could list the layer name by<br>\n",
    "```\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "    #print('input_shape: {}\\toutput_shape: {}'.format(layer.input_shape, \n",
    "                                                      layer.output_shape)) \n",
    "```\n",
    "This results in a list of all layer in VGG16 network (notice the missing FC layers as the results of setting `include_top = False`).  \n",
    "\n",
    "input_1<br>\n",
    "block1_conv1<br>\n",
    "block1_conv2<br>\n",
    "block1_pool<br>\n",
    "block2_conv1<br>\n",
    "block2_conv2<br>\n",
    "block2_pool<br>\n",
    "block3_conv1<br>\n",
    "block3_conv2<br>\n",
    "block3_conv3<br>\n",
    "block3_pool<br>\n",
    "block4_conv1<br>\n",
    "block4_conv2<br>\n",
    "block4_conv3<br>\n",
    "block4_pool<br>\n",
    "block5_conv1<br>\n",
    "block5_conv2<br>\n",
    "block5_conv3<br>\n",
    "block5_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a __loss function__ that will seek to __maximize the activation__ of a specific filter (filter_index) in a specific layer (layer_name). We do this via a Keras backend function, which allows our code to run both on top of TensorFlow and Theano.<br>\n",
    "```\n",
    "from keras import backend as K\n",
    "```\n",
    "`layer_name` can be set using following `layer.name` of any layer with filter. For example,\n",
    "```\n",
    "layer_name = 'block5_conv3'\n",
    "```\n",
    "`filter_index` can be set to any integer that corresponds to the filter index in that layer. For example, there are 512 filters for `block5_conv3`. Thus, we can set the index to any value between 0 and 511."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "layer_name = 'block5_conv3'\n",
    "filter_index  = 0 # can be any integer from 0 to 511, as there are 512 filters\n",
    "\n",
    "# build a loss function that maximises the activation of the nth filter of the chosen layer\n",
    "# 1. obtain the output of the selected layer 'layer_name'\n",
    "layer_output = layer_dict[layer_name].output \n",
    "# 2. Get the mean of the tensor at filter_index \n",
    "if K.image_data_format() == 'channels_first':\n",
    "    loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "else:    \n",
    "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "# Define the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# compute the gradient of the input picture wrt this loss\n",
    "grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "# normalise the gradient\n",
    "small_value = 1e-5 # or K.epsilon()\n",
    "grads /= (K.sqrt(K.mean(K.square(grads))) + small_value)\n",
    "\n",
    "# This function returns the loss and grads given the input picture\n",
    "iterate = K.function([input_img], [loss, grads])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, __the gradient of the pixels of the input image is normalised__. This avoids very small and very large gradients which ensure smooth gradient ascent process.<br><br>\n",
    "Next, we use the Keras function we defined to do __gradient ascent__ in the input space, with regard to our filter activation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 3)\n",
      "Current loss value: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supannee/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imsave\n",
    "\n",
    "# Let's define dimensions of the generated pictures for each filter.\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "\n",
    "# Let's start from a gray image with some noise\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "else:\n",
    "    input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "imsave('gray_image.png', input_img_data[0,:,:,:])\n",
    "print(input_img_data.shape)\n",
    "\n",
    "# run gradient ascent for N steps\n",
    "N = 20    \n",
    "step = 1. # step size for gradient ascent\n",
    "for i in range(N):\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    input_img_data += grads_value * step\n",
    "    \n",
    "    print('Current loss value:', loss_value)\n",
    "    if loss_value <= 0.:\n",
    "        # some filter get stuck to 0, skip them\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract and display the generated input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalise tensor: center at 0., and std at 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + small_value)\n",
    "    x *= 0.1\n",
    "    \n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "    \n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first': # c,h,w\n",
    "        x = x.transpose((1, 2, 0)) # results in h,w,c\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to run and get the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supannee/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "img = input_img_data[0]\n",
    "img = deprocess_image(img)\n",
    "imsave('%s_filter_%d.png' % (layer_name, filter_index), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Input image:__<br>\n",
    "![Input image](gray_image.png)\n",
    "\n",
    "__Result:__ <br>\n",
    "![Result image](block5_conv3_filter_0.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
